apiVersion: apps/v1
kind: Deployment
metadata:
  name: nginx
  labels:
    app: nginx
spec:
  selector:
    matchLabels:
      app: nginx
  replicas: 1
  template:
    metadata:
      labels:
        app: nginx
    spec:
      containers:
        - name: nginx
          image: nginx:alpine
          ports:
            - containerPort: 80
          volumeMounts:
            - mountPath: /etc/nginx/nginx.conf
              subPath: nginx.conf
              readOnly: true
              name: nginx-conf
            - mountPath: /etc/nginx/password.conf
              subPath: password.conf
              readOnly: true
              name: password-conf
            - mountPath: /usr/share/nginx/html # mount nginx-htmlroot volume to /usr/share/nginx/html
              readOnly: true
              name: nginx-htmlroot

        - name: hadoop-namenode
          image: bde2020/hadoop-namenode:2.0.0-hadoop3.2.1-java8
          ports:
            - containerPort: 9870 # WebUI for NameNode default 9870/9871
            - containerPort: 9000
          env:
            - name: CLUSTER_NAME
              value: test
            - name: hadoop-env
              valueFrom:
                configMapKeyRef:
                  name: confnginx
                  key: hadoop.env
          volumeMounts:
            - mountPath: /hadoop/dfs/name
              name: hadoop-namenode

        - name: hadoop-datanode
          image: bde2020/hadoop-datanode:2.0.0-hadoop3.2.1-java8
          ports:
            - containerPort: 9864
          env:
            - name: SERVICE_PRECONDITION
              value: "namenode:9870"
            - name: hadoop-env
              valueFrom:
                configMapKeyRef:
                  name: confnginx
                  key: hadoop.env
          volumeMounts:
            - mountPath: /hadoop/dfs/data
              name: hadoop-datanode
        
        - name: hadoop-resourcemanager
          image: bde2020/hadoop-resourcemanager:2.0.0-hadoop3.2.1-java8
          env:
            - name: SERVICE_PRECONDITION
              value: "namenode:9000 namenode:9870 datanode:9864"
            - name: hadoop-env
              valueFrom:
                configMapKeyRef:
                  name: confnginx
                  key: hadoop.env

        - name: hadoop-nodemanager
          image: bde2020/hadoop-nodemanager:2.0.0-hadoop3.2.1-java8
          ports:
            - containerPort: 8088
          env:
            - name: SERVICE_PRECONDITION
              value: "namenode:9000 namenode:9870 datanode:9864 resourcemanager:8088"
            - name: hadoop-env
              valueFrom:
                configMapKeyRef:
                  name: confnginx
                  key: hadoop.env

        - name: hadoop-historyserver
          image: bde2020/hadoop-historyserver:2.0.0-hadoop3.2.1-java8
          env:
            - name: SERVICE_PRECONDITION
              value: "namenode:9000 namenode:9870 datanode:9864 resourcemanager:8088"
            - name: hadoop-env
              valueFrom:
                configMapKeyRef:
                  name: confnginx
                  key: hadoop.env
          volumeMounts:
            - name: hadoop-historyserver
              mountPath: /hadoop/yarn/timeline

      volumes:
        - name: nginx-conf
          configMap:
            name: confnginx
            items:
              - key: nginx.conf
                path: nginx.conf
        - name: password-conf
          configMap:
            name: confnginx
            items:
              - key: password.conf
                path: password.conf
        - name: nginx-htmlroot
          configMap:
            name: confnginx
            items:
              - key: index.html
                path: index.html

        - name: hadoop-namenode
          hostPath:
            path: /hadoop/dfs/name
            type: DirectoryOrCreate

        - name: hadoop-datanode
          hostPath:
            path: /hadoop/dfs/data
            type: DirectoryOrCreate

        - name: hadoop-historyserver
          hostPath:
            path: /hadoop/yarn/timeline
            type: DirectoryOrCreate
---
apiVersion: v1
kind: Service
metadata:
  name: nginx
  labels:
    name: nginx
spec:
  selector:
    app: nginx
  ports:
    - protocol: TCP
      port: 80
      targetPort: 80
      name: nginx
  type: LoadBalancer
---
apiVersion: v1
kind: ConfigMap
metadata:
  name: confnginx
data:
  nginx.conf: |
    user  nginx;
    worker_processes  1;

    error_log  /var/log/nginx/error.log warn;
    pid        /var/run/nginx.pid;

    events {
        worker_connections  1024;
    }
    http {
      include       /etc/nginx/mime.types;
      
      default_type  application/octet-stream;

      log_format  main  '$remote_addr - $remote_user [$time_local] "$request" '
                          '$status $body_bytes_sent "$http_referer" '
                          '"$http_user_agent" "$http_x_forwarded_for"';

      access_log  /var/log/nginx/access.log  main;

      sendfile        on;

      keepalive_timeout  65;

      server {
        listen 80;
        listen [::]:80;
        server_name localhost;

        proxy_set_header Host $host;
        proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;

        proxy_cache_revalidate on;
        proxy_cache_use_stale error timeout http_500 http_502 http_503 http_504;
        proxy_cache_background_update on;
        proxy_cache_lock on;

        index index.html;

        resolver kube-dns.kube-system.svc.cluster.local valid=5s;

        auth_basic "Access restricted";
        auth_basic_user_file /etc/nginx/password.conf;

        location /hadoop/ {
          proxy_set_header Host $http_host/hadoop;
          proxy_redirect off;
          rewrite ^/hadoop/(.*)$ /$1 break;
          proxy_pass http://127.0.0.1:9870/;
          sub_filter 'action="/'  'action="/hadoop/';
          sub_filter 'href="/'    'href="/hadoop/';
          sub_filter 'src="/'     'src="/hadoop/';
          sub_filter_once off;
        }

        location /health {
          return 200;
        }

        location / {
          root /usr/share/nginx/html;
          index index.html index.htm;
        }

      }
    }
  password.conf: |
        bekdestester:$6$8tHKH5TSh$FbIquguOZIvMzc52APCPGaVUq8N2vhmQlsxfV7PIiVJNTzKWRRrkHqbFsY4DfTqHNZNcejO.dOGpgdwPzzNG80
        firelay:$6$2SpUcpng9JqnLOO9$5oLMFZOQdNjqTeUBGW8Tf0.mw0unAlVuqh8Dt4cHpsa4EzAMDTL1ylKSNErURDO3QqN0f/Gdyg5sUhYhWKYCu.
  index.html: |
    <html>
    <body>
    <p>Some secrets:</p>
    <ul>
    <li><pre>username: .Data.username </pre></li>
    <li><pre>password: .Data.password </pre></li>
    <li><a href='/hadoop'>Hadoop</a></li>
    </ul>
    </body>
    </html>
  hadoop.env: |
    CORE_CONF_fs_defaultFS=hdfs://namenode:9000
    CORE_CONF_hadoop_http_staticuser_user=root
    CORE_CONF_hadoop_proxyuser_hue_hosts=*
    CORE_CONF_hadoop_proxyuser_hue_groups=*
    CORE_CONF_io_compression_codecs=org.apache.hadoop.io.compress.SnappyCodec

    HDFS_CONF_dfs_webhdfs_enabled=true
    HDFS_CONF_dfs_permissions_enabled=false
    HDFS_CONF_dfs_namenode_datanode_registration_ip___hostname___check=false

    YARN_CONF_yarn_log___aggregation___enable=true
    YARN_CONF_yarn_log_server_url=http://historyserver:8188/applicationhistory/logs/
    YARN_CONF_yarn_resourcemanager_recovery_enabled=true
    YARN_CONF_yarn_resourcemanager_store_class=org.apache.hadoop.yarn.server.resourcemanager.recovery.FileSystemRMStateStore
    YARN_CONF_yarn_resourcemanager_scheduler_class=org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler
    YARN_CONF_yarn_scheduler_capacity_root_default_maximum___allocation___mb=8192
    YARN_CONF_yarn_scheduler_capacity_root_default_maximum___allocation___vcores=4
    YARN_CONF_yarn_resourcemanager_fs_state___store_uri=/rmstate
    YARN_CONF_yarn_resourcemanager_system___metrics___publisher_enabled=true
    YARN_CONF_yarn_resourcemanager_hostname=resourcemanager
    YARN_CONF_yarn_resourcemanager_address=resourcemanager:8032
    YARN_CONF_yarn_resourcemanager_scheduler_address=resourcemanager:8030
    YARN_CONF_yarn_resourcemanager_resource__tracker_address=resourcemanager:8031
    YARN_CONF_yarn_timeline___service_enabled=true
    YARN_CONF_yarn_timeline___service_generic___application___history_enabled=true
    YARN_CONF_yarn_timeline___service_hostname=historyserver
    YARN_CONF_mapreduce_map_output_compress=true
    YARN_CONF_mapred_map_output_compress_codec=org.apache.hadoop.io.compress.SnappyCodec
    YARN_CONF_yarn_nodemanager_resource_memory___mb=16384
    YARN_CONF_yarn_nodemanager_resource_cpu___vcores=8
    YARN_CONF_yarn_nodemanager_disk___health___checker_max___disk___utilization___per___disk___percentage=98.5
    YARN_CONF_yarn_nodemanager_remote___app___log___dir=/app-logs
    YARN_CONF_yarn_nodemanager_aux___services=mapreduce_shuffle

    MAPRED_CONF_mapreduce_framework_name=yarn
    MAPRED_CONF_mapred_child_java_opts=-Xmx4096m
    MAPRED_CONF_mapreduce_map_memory_mb=4096
    MAPRED_CONF_mapreduce_reduce_memory_mb=8192
    MAPRED_CONF_mapreduce_map_java_opts=-Xmx3072m
    MAPRED_CONF_mapreduce_reduce_java_opts=-Xmx6144m
    MAPRED_CONF_yarn_app_mapreduce_am_env=HADOOP_MAPRED_HOME=/opt/hadoop-3.2.1/
    MAPRED_CONF_mapreduce_map_env=HADOOP_MAPRED_HOME=/opt/hadoop-3.2.1/
    MAPRED_CONF_mapreduce_reduce_env=HADOOP_MAPRED_HOME=/opt/hadoop-3.2.1/
---