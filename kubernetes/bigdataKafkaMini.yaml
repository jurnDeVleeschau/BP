apiVersion: apps/v1
kind: Deployment
metadata:
  name: bigdata-kafka
  labels:
    app: bigdata-kafka
spec:
  selector:
    matchLabels:
      app: bigdata-kafka
  replicas: 1
  template:
    metadata:
      labels:
        app: bigdata-kafka
    spec:
      containers:
        - name: nginx
          image: nginx:alpine
          ports:
            - containerPort: 443
          volumeMounts:
            - mountPath: /etc/nginx/nginx.conf
              subPath: nginx.conf
              readOnly: true
              name: nginx-conf
            - mountPath: /etc/nginx/password.conf
              subPath: password.conf
              readOnly: true
              name: password-conf
            - mountPath: /etc/nginx/ssl
              readOnly: true
              name: nginx-secret-volume
            - mountPath: /usr/share/nginx/html # mount nginx-htmlroot volume to /usr/share/nginx/html
              readOnly: true
              name: nginx-htmlroot

        - name: zookeeper
          image: confluentinc/cp-zookeeper:7.2.2
          ports:
            - containerPort: 2181
          env:
            - name: ZOOKEEPER_CLIENT_PORT
              value: "2181"
            - name: ZOOKEEPER_SERVER_ID
              value: "1"
            - name: KAFKA_OPTS
              value: "-Djava.security.auth.login.config=/KAFKA_HOME/config/zookeeper_jaas.conf"
          volumeMounts:
            - mountPath: /KAFKA_HOME/config/zookeeper_jaas.conf
              subPath: zookeeper_jaas.conf
              readOnly: true
              name: zookeeper-jaasconf
            - mountPath: /config/zookeeper.properties
              subPath: zookeeper.properties
              readOnly: true
              name: zookeeperproperties

        - name: kafka1
          image: confluentinc/cp-kafka:7.2.2
          ports:
            - containerPort: 9092
            - containerPort: 29092
            - containerPort: 19092
          env:
            - name: KAFKA_ADVERTISED_LISTENERS
              value: "INTERNAL://localhost:19092,EXTERNAL://127.0.0.1:9092,DOCKER://localhost:29092"
            - name: KAFKA_BROKER_ID
              value: "1"
            - name: KAFKA_OPTS
              value: "-Djava.security.auth.login.config=/KAFKA_HOME/config/kafka_server_jaas.conf"
          envFrom:
            - configMapRef:
                name: confkafka
          volumeMounts:
            - mountPath: /KAFKA_HOME/config/kafka_server_jaas.conf
              subPath: kafka_server_jaas.conf
              readOnly: true
              name: kafka-server-jaasconf
            - mountPath: /config/consumer.properties
              subPath: consumerproperties
              readOnly: true
              name: consumerproperties
            - mountPath: /config/producer.properties
              subPath: producer.properties
              readOnly: true
              name: producerproperties
            - mountPath: /config/server.properties
              subPath: server.properties
              readOnly: true
              name: serverproperties

              

        - name: kafka-schema-registry
          image: confluentinc/cp-schema-registry:7.2.2
          ports:
            - containerPort: 8081
          env:
            - name: SCHEMA_REGISTRY_HOST_NAME
              value: "kafka-schema-registry"
            - name: SCHEMA_REGISTRY_KAFKASTORE_BOOTSTRAP_SERVERS
              value: 'PLAINTEXT://localhost:19092'
            - name: SCHEMA_REGISTRY_LISTENERS
              value: "http://0.0.0.0:8081"

      volumes:
        - name: nginx-conf
          configMap:
            name: confnginx
            items:
              - key: nginx.conf
                path: nginx.conf
        - name: password-conf
          configMap:
            name: confnginx
            items:
              - key: password.conf
                path: password.conf
        - name: nginx-secret-volume
          secret:
            secretName: nginxsecret
        - name: nginx-htmlroot
          configMap:
            name: confnginx
            items:
              - key: index.html
                path: index.html

        - name: zookeeper-jaasconf
          configMap:
            name: confnginx
            items:
              - key: zookeeper_jaas.conf
                path: zookeeper_jaas.conf

        - name: kafka-server-jaasconf
          configMap:
            name: confnginx
            items:
              - key: kafka_server_jaas.conf
                path: kafka_server_jaas.conf
        - name: consumerproperties
          configMap:
            name: confnginx
            items:
              - key: consumer.properties
                path: consumer.properties
        - name: producerproperties
          configMap:
            name: confnginx
            items:
              - key: producer.properties
                path: producer.properties
        - name: zookeeperproperties
          configMap:
            name: confnginx
            items:
              - key: zookeeper.properties
                path: zookeeper.properties
        - name: serverproperties
          configMap:
            name: confnginx
            items:
              - key: server.properties
                path: server.properties
---
apiVersion: v1
kind: Service
metadata:
  name: bigdata-kafka
  labels:
    name: bigdata-kafka
spec:
  selector:
    app: bigdata-kafka
  ports:
    - protocol: TCP
      port: 443
      targetPort: 443
      name: bigdata-kafka
  type: LoadBalancer
---
apiVersion: v1
kind: ConfigMap
metadata:
  name: confnginx
data:
  nginx.conf: |
    user  nginx;
    worker_processes  1;

    error_log  /var/log/nginx/error.log warn;
    pid        /var/run/nginx.pid;

    events {
        worker_connections  1024;
    }
    http {
      include       /etc/nginx/mime.types;
      
      default_type  application/octet-stream;

      log_format  main  '$remote_addr - $remote_user [$time_local] "$request" '
                          '$status $body_bytes_sent "$http_referer" '
                          '"$http_user_agent" "$http_x_forwarded_for"';

      access_log  /var/log/nginx/access.log  main;

      sendfile        on;

      keepalive_timeout  65;

      server {
        listen 443 ssl;
        listen [::]:443 ssl;
        server_name localhost;

        ssl_certificate     /etc/nginx/ssl/tls.crt;
        ssl_certificate_key /etc/nginx/ssl/tls.key;
        ssl_protocols       TLSv1 TLSv1.1 TLSv1.2;
        ssl_ciphers         HIGH:!aNULL:!MD5;
        index index.html;

        auth_basic "Access restricted";
        auth_basic_user_file /etc/nginx/password.conf;

        location / {
          root /usr/share/nginx/html;
          index index.html index.htm;
        }

      }

      server {
        listen 443 ssl;
        listen [::]:443 ssl;
        server_name www.kafka.local;

        ssl_certificate     /etc/nginx/ssl/tls.crt;
        ssl_certificate_key /etc/nginx/ssl/tls.key;
        ssl_protocols       TLSv1 TLSv1.1 TLSv1.2;
        ssl_ciphers         HIGH:!aNULL:!MD5;

        proxy_set_header Host $host;
        proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;

        proxy_cache_revalidate on;
        proxy_cache_use_stale error timeout http_500 http_502 http_503 http_504;
        proxy_cache_background_update on;
        proxy_cache_lock on;

        resolver kube-dns.kube-system.svc.cluster.local valid=5s;

        auth_basic "Access restricted";
        auth_basic_user_file /etc/nginx/password.conf;

        location / {
          proxy_pass http://localhost:2181/;
          proxy_redirect default;
        }
      }
    }
  password.conf: |
    student1:$apr1$vkkQyFui$ntgh7QAcWoci84KV79uKe0
    student2:$apr1$xgHxj9Tp$MXcwiM4vjsM8wLX0Cy2Rz/
  index.html: |
    <html>
    <body>
    <p>Some secrets:</p>
    <ul>
    <li><pre>username: .Data.username </pre></li>
    <li><pre>password: .Data.password </pre></li>
    <li><a href='/kafka'>kafka</a></li>
    </ul>
    </body>
    </html>
  server.properties: |
    security.inter.broker.protocol=SASL_PLAINTEXT
    sasl.mechanism.inter.broker.protocol=PLAIN
    sasl.enabled.mechanisms=PLAIN

    authorizer.class.name=kafka.security.auth.SimpleAclAuthorizer
    allow.everyone.if.no.acl.found=true
    auto.create.topics.enable=false
    listeners=SASL_PLAINTEXT://localhost:9092
    advertised.listeners=SASL_PLAINTEXT://localhost:9092

    advertised.host.name=localhost
    zookeeper.connect=localhost:2181
  zookeeper.properties: |
    authProvider.1=org.apache.zookeeper.server.auth.SASLAuthenticationProvider
    requireClientAuthScheme=sasl
    jaasLoginRenew=3600000
    clientPort=2181
  consumer.properties: |
    security.protocol=SASL_PLAINTEXT
    sasl.mechanism=PLAIN
    zookeeper.connect=localhost:2181
  producer.properties: |
    sasl.mechanism=PLAIN
    security.protocol=SASL_PLAINTEXT
    sasl.jaas.config=org.apache.kafka.common.security.plain.PlainLoginModule required
    username="admin"
    password="admin-secret";
    bootstrap.servers=localhost:9092
  zookeeper_jaas.conf: |
    Server {
      org.apache.kafka.common.security.plain.PlainLoginModule required
      username="admin"
      password="admin-secret"
      user_admin="admin-secret";
    };
    Client {
      org.apache.zookeeper.server.auth.DigestLoginModule required
      username="admin"
      password="admin-secret";
    };
  kafka_server_jaas.conf: |
    KafkaServer {
       org.apache.kafka.common.security.plain.PlainLoginModule required
       username="admin"
       password="admin-secret"
       user_admin="admin-secret";
    };

    Client {
       org.apache.kafka.common.security.plain.PlainLoginModule required
       username="admin"
       password="admin-secret";
    };
---
apiVersion: v1
kind: ConfigMap
metadata:
  name: confkafka
data:
  KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: "INTERNAL:PLAINTEXT,EXTERNAL:PLAINTEXT,DOCKER:PLAINTEXT"
  KAFKA_INTER_BROKER_LISTENER_NAME: "INTERNAL"
  KAFKA_ZOOKEEPER_CONNECT: "localhost:2181"
  KAFKA_LOG4J_LOGGERS: "kafka.controller=INFO,kafka.producer.async.DefaultEventHandler=INFO,state.change.logger=INFO"
  KAFKA_AUTHORIZER_CLASS_NAME: "kafka.security.authorizer.AclAuthorizer"
  KAFKA_ALLOW_EVERYONE_IF_NO_ACL_FOUND: "true"
  KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: "1"
---